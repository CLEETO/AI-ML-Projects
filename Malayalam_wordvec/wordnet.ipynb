{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21:12:52:13,295 INFO     [utils.py:161] NumExpr defaulting to 16 threads.\n"
     ]
    }
   ],
   "source": [
    "import pyiwn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Language.ASSAMESE: 'assamese'>,\n",
       " <Language.BENGALI: 'bengali'>,\n",
       " <Language.BODO: 'bodo'>,\n",
       " <Language.GUJARATI: 'gujarati'>,\n",
       " <Language.HINDI: 'hindi'>,\n",
       " <Language.KANNADA: 'kannada'>,\n",
       " <Language.KASHMIRI: 'kashmiri'>,\n",
       " <Language.KONKANI: 'konkani'>,\n",
       " <Language.MALAYALAM: 'malayalam'>,\n",
       " <Language.MARATHI: 'marathi'>,\n",
       " <Language.MEITEI: 'meitei'>,\n",
       " <Language.NEPALI: 'nepali'>,\n",
       " <Language.ORIYA: 'oriya'>,\n",
       " <Language.PUNJABI: 'punjabi'>,\n",
       " <Language.SANSKRIT: 'sanskrit'>,\n",
       " <Language.TAMIL: 'tamil'>,\n",
       " <Language.TELUGU: 'telugu'>,\n",
       " <Language.URDU: 'urdu'>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pyiwn.Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21:12:52:15,292 INFO     [iwn.py:43] Loading malayalam language synsets...\n"
     ]
    }
   ],
   "source": [
    "iwn = pyiwn.IndoWordNet(lang=pyiwn.Language.MALAYALAM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40773\n",
      "30140\n"
     ]
    }
   ],
   "source": [
    "words = iwn.all_words()\n",
    "print(len(words))\n",
    "words = iwn.all_synsets()\n",
    "print(len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<SynsetRelations.MERO_MEMBER_COLLECTION: 'mero_member_collection'>,\n",
       " <SynsetRelations.ABILITY_VERB: 'ability_verb'>,\n",
       " <SynsetRelations.CAUSATIVE: 'causative'>,\n",
       " <SynsetRelations.CAPABILITY_VERB: 'capability_verb'>,\n",
       " <SynsetRelations.MERO_COMPONENT_OBJECT: 'mero_component_object'>,\n",
       " <SynsetRelations.HOLO_PORTION_MASS: 'holo_portion_mass'>,\n",
       " <SynsetRelations.FUNCTION_VERB: 'function_verb'>,\n",
       " <SynsetRelations.HOLO_COMPONENT_OBJECT: 'holo_component_object'>,\n",
       " <SynsetRelations.HYPERNYMY: 'hypernymy'>,\n",
       " <SynsetRelations.ENTAILMENT: 'entailment'>,\n",
       " <SynsetRelations.ALSO_SEE: 'also_see'>,\n",
       " <SynsetRelations.MERO_FEATURE_ACTIVITY: 'mero_feature_activity'>,\n",
       " <SynsetRelations.HOLO_PLACE_AREA: 'holo_place_area'>,\n",
       " <SynsetRelations.MODIFIES_VERB: 'modifies_verb'>,\n",
       " <SynsetRelations.ATTRIBUTES: 'attributes'>,\n",
       " <SynsetRelations.MERO_PORTION_MASS: 'mero_portion_mass'>,\n",
       " <SynsetRelations.MODIFIES_NOUN: 'modifies_noun'>,\n",
       " <SynsetRelations.HOLO_FEATURE_ACTIVITY: 'holo_feature_activity'>,\n",
       " <SynsetRelations.MERO_STUFF_OBJECT: 'mero_stuff_object'>,\n",
       " <SynsetRelations.TROPONYMY: 'troponymy'>,\n",
       " <SynsetRelations.MERO_PLACE_AREA: 'mero_place_area'>,\n",
       " <SynsetRelations.HOLO_MEMBER_COLLECTION: 'holo_member_collection'>,\n",
       " <SynsetRelations.HYPONYMY: 'hyponymy'>,\n",
       " <SynsetRelations.SIMILAR: 'similar'>,\n",
       " <SynsetRelations.MERO_POSITION_AREA: 'mero_position_area'>,\n",
       " <SynsetRelations.HOLO_POSITION_AREA: 'holo_position_area'>,\n",
       " <SynsetRelations.HOLO_STUFF_OBJECT: 'holo_stuff_object'>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pyiwn.SynsetRelations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('ചന്ദ്രകിരണം.noun.30289')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iwn.synsets('നിലാവ്')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[]\n",
    "for synset in iwn.all_synsets():\n",
    "    sentences.append(synset.head_word().replace('.','')+' എന്നതിൻ്റെ അർത്ഥം '+synset.gloss().replace('.','')+' എന്നാണ്.')\n",
    "    for sentence in synset.examples():\n",
    "        sentences.append(sentence.replace('.',''))\n",
    "    for lemma in synset.lemmas():\n",
    "        if lemma.name().replace('.','')!=synset.head_word().replace('.',''):\n",
    "            sentences.append(lemma.name().replace('.','')+' എന്നത് '+synset.head_word().replace('.','')+' എന്നതിന്റെ ഒരേ അർത്ഥം ഉള്ള വാക്കാണ്.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.ABILITY_VERB))>0:\n",
    "        for ability_verb in iwn.synset_relation(synset, pyiwn.SynsetRelations.ABILITY_VERB):\n",
    "            if synset.head_word()!=ability_verb.head_word():\n",
    "                sentences.append(synset.head_word().replace('.','')+' '+ability_verb.head_word().replace('.','')+'യാണ്.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.CAPABILITY_VERB))>0:\n",
    "        for capability_verb in iwn.synset_relation(synset, pyiwn.SynsetRelations.CAPABILITY_VERB):\n",
    "            if synset.head_word()!=capability_verb.head_word():\n",
    "                sentences.append(synset.head_word().replace('.','')+' '+capability_verb.head_word().replace('.','')+'യാണ്.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_MEMBER_COLLECTION))>0:\n",
    "        for member in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_MEMBER_COLLECTION):\n",
    "            if synset.head_word()!=member.head_word():\n",
    "                sentences.append(member.head_word().replace('.','')+' എന്നത് '+synset.head_word().replace('.','')+' എന്നതിൻ്റെ അംഗമാണ്.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_COMPONENT_OBJECT))>0:\n",
    "        for object in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_COMPONENT_OBJECT):\n",
    "            if synset.head_word()!=object.head_word():\n",
    "                sentences.append(object.head_word().replace('.','')+' എന്നത് '+synset.head_word().replace('.','')+' എന്നതിൻ്റെ ഭാഗമാണ്.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_PORTION_MASS))>0:\n",
    "        for mass in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_PORTION_MASS):\n",
    "            if synset.head_word()!=mass.head_word():\n",
    "                sentences.append(synset.head_word().replace('.','')+' എന്നത് '+mass.head_word().replace('.','')+' എന്നതിൻ്റെ ഭാഗമാണ്.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.FUNCTION_VERB))>0:\n",
    "        for function_verb in iwn.synset_relation(synset, pyiwn.SynsetRelations.FUNCTION_VERB):\n",
    "            if synset.head_word()!=function_verb.head_word():\n",
    "                sentences.append(synset.head_word().replace('.','')+' '+function_verb.head_word().replace('.','')+'യാണ്.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_COMPONENT_OBJECT))>0:\n",
    "        for object in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_COMPONENT_OBJECT):\n",
    "            if synset.head_word()!=object.head_word():\n",
    "                sentences.append(synset.head_word().replace('.','')+' എന്നത് '+object.head_word().replace('.','')+' എന്നതിന്റെ ഭാഗമാണ്.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HYPERNYMY))>0:\n",
    "        for hypernym in iwn.synset_relation(synset, pyiwn.SynsetRelations.HYPERNYMY):\n",
    "            if synset.head_word()!=hypernym.head_word():\n",
    "                sentences.append(synset.head_word().replace('.','')+' എന്നത് '+hypernym.head_word().replace('.','')+' എന്നതിന്റെ ഉപവകിയാണ്.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.ENTAILMENT))>0:\n",
    "        for entailment in iwn.synset_relation(synset, pyiwn.SynsetRelations.ENTAILMENT):\n",
    "            if synset.head_word()!=entailment.head_word():\n",
    "                sentences.append('ഒരു വ്യക്തി '+synset.head_word().replace('.','')+'യാണെങ്കിൽ, അത് അവർ '+entailment.head_word().replace('.','')+'യാണ് എന്നതിനെ അടയാളപ്പെടുത്തുന്നു.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MODIFIES_VERB))>0:\n",
    "        for modifies_verb in iwn.synset_relation(synset, pyiwn.SynsetRelations.MODIFIES_VERB):\n",
    "            if synset.head_word()!=modifies_verb.head_word():\n",
    "                sentences.append(synset.head_word().replace('.','')+' '+modifies_verb.head_word().replace('.','')+'.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.ATTRIBUTES))>0:\n",
    "        for attribute in iwn.synset_relation(synset, pyiwn.SynsetRelations.ATTRIBUTES):\n",
    "            if synset.head_word()!=attribute.head_word():\n",
    "                sentences.append(attribute.head_word().replace('.','')+' '+synset.head_word().replace('.','')+'.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MODIFIES_NOUN))>0:\n",
    "        for modifies_noun in iwn.synset_relation(synset, pyiwn.SynsetRelations.MODIFIES_NOUN):\n",
    "            if synset.head_word()!=modifies_noun.head_word():\n",
    "                sentences.append(synset.head_word().replace('.','')+' '+modifies_noun.head_word().replace('.','')+'.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_STUFF_OBJECT))>0:\n",
    "        for object in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_STUFF_OBJECT):\n",
    "            if synset.head_word()!=object.head_word():\n",
    "                sentences.append(object.head_word().replace('.','')+' എന്നത് '+synset.head_word().replace('.','')+' എന്നതിൻ്റെ ഘടകവസ്തുവാണ്.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_MEMBER_COLLECTION))>0:\n",
    "        for object in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_MEMBER_COLLECTION):\n",
    "            if synset.head_word()!=object.head_word():\n",
    "                sentences.append(object.head_word().replace('.','')+' '+synset.head_word().replace('.','')+'കളുടെ സമാഹാരമാണ്.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HYPONYMY))>0:\n",
    "        for hyponymy in iwn.synset_relation(synset, pyiwn.SynsetRelations.HYPONYMY):\n",
    "            if synset.head_word()!=hyponymy.head_word():\n",
    "                sentences.append(hyponymy.head_word().replace('.','')+' ഒരു '+synset.head_word().replace('.','')+' ആണ്.')\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.SIMILAR))>0:\n",
    "        for similar in iwn.synset_relation(synset, pyiwn.SynsetRelations.SIMILAR):\n",
    "            if synset.head_word()!=similar.head_word():\n",
    "                sentences.append(similar.head_word().replace('.','')+' '+synset.head_word().replace('.','')+' എന്നതിനോട് സമാനമായതാണ്..')\n",
    "    \n",
    "    \n",
    "with open('malayalam_senteces1.txt','w',encoding=\"utf-8\") as f:\n",
    "    for sentence in sentences:\n",
    "        f.write('%s\\n'%sentence.replace('_',' '))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences_list=[]\n",
    "for synset in iwn.all_synsets():\n",
    "    sentences=[]\n",
    "    sentences.append(synset.head_word().replace('.',' ')+' '+synset.gloss().replace('.',''))\n",
    "\n",
    "    for sentence in synset.examples():\n",
    "        sentences_list.append(sentence.replace('.',' '))\n",
    "\n",
    "    for lemma in synset.lemmas():\n",
    "        if lemma.name().replace('.','')!=synset.head_word().replace('.',' '):\n",
    "            sentences.append(lemma.name().replace('.',' ')+' '+synset.head_word().replace('.',' '))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.ABILITY_VERB))>0:\n",
    "        for ability_verb in iwn.synset_relation(synset, pyiwn.SynsetRelations.ABILITY_VERB):\n",
    "            if synset.head_word()!=ability_verb.head_word():\n",
    "                sentences.append(synset.head_word().replace('.',' ')+' '+ability_verb.head_word().replace('.',' '))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.CAPABILITY_VERB))>0:\n",
    "        for capability_verb in iwn.synset_relation(synset, pyiwn.SynsetRelations.CAPABILITY_VERB):\n",
    "            if synset.head_word()!=capability_verb.head_word():\n",
    "                sentences.append(synset.head_word().replace('.',' ')+' '+capability_verb.head_word().replace('.',' '))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_MEMBER_COLLECTION))>0:\n",
    "        for member in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_MEMBER_COLLECTION):\n",
    "            if synset.head_word()!=member.head_word():\n",
    "                sentences.append(member.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_COMPONENT_OBJECT))>0:\n",
    "        for object in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_COMPONENT_OBJECT):\n",
    "            if synset.head_word()!=object.head_word():\n",
    "                sentences.append(object.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_PORTION_MASS))>0:\n",
    "        for mass in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_PORTION_MASS):\n",
    "            if synset.head_word()!=mass.head_word():\n",
    "                sentences.append(synset.head_word().replace('.','')+' '+mass.head_word().replace('.',''))\n",
    "\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HYPERNYMY))>0:\n",
    "        for hypernym in iwn.synset_relation(synset, pyiwn.SynsetRelations.HYPERNYMY):\n",
    "            if synset.head_word()!=hypernym.head_word():\n",
    "                sentences.append(synset.head_word().replace('.','')+' '+hypernym.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.ENTAILMENT))>0:\n",
    "        for entailment in iwn.synset_relation(synset, pyiwn.SynsetRelations.ENTAILMENT):\n",
    "            if synset.head_word()!=entailment.head_word():\n",
    "                sentences.append(synset.head_word().replace('.','')+' '+entailment.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MODIFIES_VERB))>0:\n",
    "        for modifies_verb in iwn.synset_relation(synset, pyiwn.SynsetRelations.MODIFIES_VERB):\n",
    "            if synset.head_word()!=modifies_verb.head_word():\n",
    "                sentences.append(synset.head_word().replace('.','')+' '+modifies_verb.head_word().replace('.','')+'.')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.ATTRIBUTES))>0:\n",
    "        for attribute in iwn.synset_relation(synset, pyiwn.SynsetRelations.ATTRIBUTES):\n",
    "            if synset.head_word()!=attribute.head_word():\n",
    "                sentences.append(attribute.head_word().replace('.','')+' '+synset.head_word().replace('.','')+'.')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MODIFIES_NOUN))>0:\n",
    "        for modifies_noun in iwn.synset_relation(synset, pyiwn.SynsetRelations.MODIFIES_NOUN):\n",
    "            if synset.head_word()!=modifies_noun.head_word():\n",
    "                sentences.append(synset.head_word().replace('.','')+' '+modifies_noun.head_word().replace('.','')+'.')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_STUFF_OBJECT))>0:\n",
    "        for object in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_STUFF_OBJECT):\n",
    "            if synset.head_word()!=object.head_word():\n",
    "                sentences.append(object.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_MEMBER_COLLECTION))>0:\n",
    "        for object in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_MEMBER_COLLECTION):\n",
    "            if synset.head_word()!=object.head_word():\n",
    "                sentences.append(object.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HYPONYMY))>0:\n",
    "        for hyponymy in iwn.synset_relation(synset, pyiwn.SynsetRelations.HYPONYMY):\n",
    "            if synset.head_word()!=hyponymy.head_word():\n",
    "                sentences.append(hyponymy.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.SIMILAR))>0:\n",
    "        for similar in iwn.synset_relation(synset, pyiwn.SynsetRelations.SIMILAR):\n",
    "            if synset.head_word()!=similar.head_word():\n",
    "                sentences.append(similar.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.CAUSATIVE))>0:\n",
    "        for causative in iwn.synset_relation(synset, pyiwn.SynsetRelations.CAUSATIVE):\n",
    "            if synset.head_word()!=causative.head_word():\n",
    "                sentences.append(causative.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.ALSO_SEE))>0:\n",
    "        for also_see in iwn.synset_relation(synset, pyiwn.SynsetRelations.ALSO_SEE):\n",
    "            if synset.head_word()!=also_see.head_word():\n",
    "                sentences.append(also_see.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_FEATURE_ACTIVITY))>0:\n",
    "        for mero_feature_activity in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_FEATURE_ACTIVITY):\n",
    "            if synset.head_word()!=mero_feature_activity.head_word():\n",
    "                sentences.append(mero_feature_activity.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_PLACE_AREA))>0:\n",
    "        for holo_place_area in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_PLACE_AREA):\n",
    "            if synset.head_word()!=holo_place_area.head_word():\n",
    "                sentences.append(holo_place_area.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_PORTION_MASS))>0:\n",
    "        for mero_portion_mass in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_PORTION_MASS):\n",
    "            if synset.head_word()!=mero_portion_mass.head_word():\n",
    "                sentences.append(mero_portion_mass.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "    \n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_FEATURE_ACTIVITY))>0:\n",
    "        for holo_feature_activity in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_FEATURE_ACTIVITY):\n",
    "            if synset.head_word()!=holo_feature_activity.head_word():\n",
    "                sentences.append(holo_feature_activity.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.TROPONYMY))>0:\n",
    "        for troponymy in iwn.synset_relation(synset, pyiwn.SynsetRelations.TROPONYMY):\n",
    "            if synset.head_word()!=troponymy.head_word():\n",
    "                sentences.append(troponymy.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_PLACE_AREA))>0:\n",
    "        for mero_place_area in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_PLACE_AREA):\n",
    "            if synset.head_word()!=mero_place_area.head_word():\n",
    "                sentences.append(mero_place_area.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_POSITION_AREA))>0:\n",
    "        for mero_position_area in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_POSITION_AREA):\n",
    "            if synset.head_word()!=mero_position_area.head_word():\n",
    "                sentences.append(mero_position_area.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_STUFF_OBJECT))>0:\n",
    "        for holo_stuff_object in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_STUFF_OBJECT):\n",
    "            if synset.head_word()!=holo_stuff_object.head_word():\n",
    "                sentences.append(holo_stuff_object.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.FUNCTION_VERB))>0:\n",
    "        for holo_stuff_object in iwn.synset_relation(synset, pyiwn.SynsetRelations.FUNCTION_VERB):\n",
    "            if synset.head_word()!=holo_stuff_object.head_word():\n",
    "                sentences.append(holo_stuff_object.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_COMPONENT_OBJECT))>0:\n",
    "        for holo_stuff_object in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_COMPONENT_OBJECT):\n",
    "            if synset.head_word()!=holo_stuff_object.head_word():\n",
    "                sentences.append(holo_stuff_object.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_POSITION_AREA))>0:\n",
    "        for holo_stuff_object in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_POSITION_AREA):\n",
    "            if synset.head_word()!=holo_stuff_object.head_word():\n",
    "                sentences.append(holo_stuff_object.head_word().replace('.','')+' '+synset.head_word().replace('.',''))\n",
    "\n",
    "\n",
    "    sentences_list.append(' '.join(sentences))\n",
    "import re  \n",
    "with open('malayalam_senteces2.txt','w',encoding=\"utf-8\") as f:\n",
    "    for sentence in sentences_list:\n",
    "        f.write(re.sub(r'[^\\u0D00-\\u0D7F\\s]', ' ', sentence)+'\\n')    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences_list=[]\n",
    "for synset in iwn.all_synsets():\n",
    "    sentences=[]\n",
    "    sentences.append(synset.head_word().replace('.',' ')+' '+synset.gloss().replace('.',''))\n",
    "\n",
    "    for sentence in synset.examples():\n",
    "        sentences_list.append(sentence.replace('.',' '))\n",
    "\n",
    "    for lemma in synset.lemmas():\n",
    "        if lemma.name().replace('.','')!=synset.head_word().replace('.',' '):\n",
    "            sentences.append(' '+lemma.name().replace('.',' '))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.ABILITY_VERB))>0:\n",
    "        for ability_verb in iwn.synset_relation(synset, pyiwn.SynsetRelations.ABILITY_VERB):\n",
    "            if synset.head_word()!=ability_verb.head_word():\n",
    "                sentences.append(' '+ability_verb.head_word().replace('.',' '))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.CAPABILITY_VERB))>0:\n",
    "        for capability_verb in iwn.synset_relation(synset, pyiwn.SynsetRelations.CAPABILITY_VERB):\n",
    "            if synset.head_word()!=capability_verb.head_word():\n",
    "                sentences.append(' '+capability_verb.head_word().replace('.',' '))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_MEMBER_COLLECTION))>0:\n",
    "        for member in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_MEMBER_COLLECTION):\n",
    "            if synset.head_word()!=member.head_word():\n",
    "                sentences.append(' '+member.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_COMPONENT_OBJECT))>0:\n",
    "        for object in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_COMPONENT_OBJECT):\n",
    "            if synset.head_word()!=object.head_word():\n",
    "                sentences.append(object.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_PORTION_MASS))>0:\n",
    "        for mass in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_PORTION_MASS):\n",
    "            if synset.head_word()!=mass.head_word():\n",
    "                sentences.append(' '+mass.head_word().replace('.',''))\n",
    "\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HYPERNYMY))>0:\n",
    "        for hypernym in iwn.synset_relation(synset, pyiwn.SynsetRelations.HYPERNYMY):\n",
    "            if synset.head_word()!=hypernym.head_word():\n",
    "                sentences.append(' '+hypernym.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.ENTAILMENT))>0:\n",
    "        for entailment in iwn.synset_relation(synset, pyiwn.SynsetRelations.ENTAILMENT):\n",
    "            if synset.head_word()!=entailment.head_word():\n",
    "                sentences.append(' '+entailment.head_word().replace('.',''))\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MODIFIES_VERB))>0:\n",
    "        for modifies_verb in iwn.synset_relation(synset, pyiwn.SynsetRelations.MODIFIES_VERB):\n",
    "            if synset.head_word()!=modifies_verb.head_word():\n",
    "                sentences.append(' '+modifies_verb.head_word().replace('.','')+'.')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.ATTRIBUTES))>0:\n",
    "        for attribute in iwn.synset_relation(synset, pyiwn.SynsetRelations.ATTRIBUTES):\n",
    "            if synset.head_word()!=attribute.head_word():\n",
    "                sentences.append(' '+attribute.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MODIFIES_NOUN))>0:\n",
    "        for modifies_noun in iwn.synset_relation(synset, pyiwn.SynsetRelations.MODIFIES_NOUN):\n",
    "            if synset.head_word()!=modifies_noun.head_word():\n",
    "                sentences.append(' '+modifies_noun.head_word().replace('.','')+'.')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_STUFF_OBJECT))>0:\n",
    "        for object in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_STUFF_OBJECT):\n",
    "            if synset.head_word()!=object.head_word():\n",
    "                sentences.append(' '+object.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_MEMBER_COLLECTION))>0:\n",
    "        for object in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_MEMBER_COLLECTION):\n",
    "            if synset.head_word()!=object.head_word():\n",
    "                sentences.append(object.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HYPONYMY))>0:\n",
    "        for hyponymy in iwn.synset_relation(synset, pyiwn.SynsetRelations.HYPONYMY):\n",
    "            if synset.head_word()!=hyponymy.head_word():\n",
    "                sentences.append(hyponymy.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.SIMILAR))>0:\n",
    "        for similar in iwn.synset_relation(synset, pyiwn.SynsetRelations.SIMILAR):\n",
    "            if synset.head_word()!=similar.head_word():\n",
    "                sentences.append(similar.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.CAUSATIVE))>0:\n",
    "        for causative in iwn.synset_relation(synset, pyiwn.SynsetRelations.CAUSATIVE):\n",
    "            if synset.head_word()!=causative.head_word():\n",
    "                sentences.append(causative.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.ALSO_SEE))>0:\n",
    "        for also_see in iwn.synset_relation(synset, pyiwn.SynsetRelations.ALSO_SEE):\n",
    "            if synset.head_word()!=also_see.head_word():\n",
    "                sentences.append(also_see.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_FEATURE_ACTIVITY))>0:\n",
    "        for mero_feature_activity in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_FEATURE_ACTIVITY):\n",
    "            if synset.head_word()!=mero_feature_activity.head_word():\n",
    "                sentences.append(mero_feature_activity.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_PLACE_AREA))>0:\n",
    "        for holo_place_area in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_PLACE_AREA):\n",
    "            if synset.head_word()!=holo_place_area.head_word():\n",
    "                sentences.append(holo_place_area.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_PORTION_MASS))>0:\n",
    "        for mero_portion_mass in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_PORTION_MASS):\n",
    "            if synset.head_word()!=mero_portion_mass.head_word():\n",
    "                sentences.append(mero_portion_mass.head_word().replace('.','')+' ')\n",
    "    \n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_FEATURE_ACTIVITY))>0:\n",
    "        for holo_feature_activity in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_FEATURE_ACTIVITY):\n",
    "            if synset.head_word()!=holo_feature_activity.head_word():\n",
    "                sentences.append(holo_feature_activity.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.TROPONYMY))>0:\n",
    "        for troponymy in iwn.synset_relation(synset, pyiwn.SynsetRelations.TROPONYMY):\n",
    "            if synset.head_word()!=troponymy.head_word():\n",
    "                sentences.append(troponymy.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_PLACE_AREA))>0:\n",
    "        for mero_place_area in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_PLACE_AREA):\n",
    "            if synset.head_word()!=mero_place_area.head_word():\n",
    "                sentences.append(mero_place_area.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_POSITION_AREA))>0:\n",
    "        for mero_position_area in iwn.synset_relation(synset, pyiwn.SynsetRelations.MERO_POSITION_AREA):\n",
    "            if synset.head_word()!=mero_position_area.head_word():\n",
    "                sentences.append(mero_position_area.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_STUFF_OBJECT))>0:\n",
    "        for holo_stuff_object in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_STUFF_OBJECT):\n",
    "            if synset.head_word()!=holo_stuff_object.head_word():\n",
    "                sentences.append(holo_stuff_object.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.FUNCTION_VERB))>0:\n",
    "        for holo_stuff_object in iwn.synset_relation(synset, pyiwn.SynsetRelations.FUNCTION_VERB):\n",
    "            if synset.head_word()!=holo_stuff_object.head_word():\n",
    "                sentences.append(holo_stuff_object.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_COMPONENT_OBJECT))>0:\n",
    "        for holo_stuff_object in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_COMPONENT_OBJECT):\n",
    "            if synset.head_word()!=holo_stuff_object.head_word():\n",
    "                sentences.append(holo_stuff_object.head_word().replace('.','')+' ')\n",
    "\n",
    "    if len(iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_POSITION_AREA))>0:\n",
    "        for holo_stuff_object in iwn.synset_relation(synset, pyiwn.SynsetRelations.HOLO_POSITION_AREA):\n",
    "            if synset.head_word()!=holo_stuff_object.head_word():\n",
    "                sentences.append(holo_stuff_object.head_word().replace('.','')+' ')\n",
    "\n",
    "\n",
    "    sentences_list.append(' '.join(sentences))\n",
    "import re\n",
    "with open('malayalam_senteces2.txt','w',encoding=\"utf-8\") as f:\n",
    "    for sentence in sentences_list:\n",
    "        f.write(re.sub(r'[^\\u0D00-\\u0D7F\\s]', ' ', sentence)+'\\n')    \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
